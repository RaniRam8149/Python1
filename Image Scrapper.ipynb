{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos.\n",
    "def extract_video_urls(thumbnail_urls):\n",
    "    video_urls = []\n",
    "    for thumbnail_url in thumbnail_urls:\n",
    "        video_url = thumbnail_url.replace('/hqdefault.jpg', '')  \n",
    "        video_urls.append(video_url)\n",
    "    return video_urls\n",
    "\n",
    "thumbnail_urls = [\n",
    "    \"https://i.ytimg.com/vi/MwVGbIC5qj0/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&amp;rs=AOn4CLCjBMwmAcVmCS-N9q7pwFM03p5clA\",\n",
    "    \"https://i.ytimg.com/vi/9Yt1qj_Bx4Y/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&amp;rs=AOn4CLCtH2O5_vwlCHqSrHAE0nvJ2tVD5A\",\n",
    "    \"https://i.ytimg.com/vi/gkguIT1XCo4/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLDB93TeXq6-3g3Hm5080lg4dbwXAA\",\n",
    "    \"https://i.ytimg.com/vi/CCw6oto2WlA/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLBzio66Im5GyBY6V5hs-48_1iaBUA\",\n",
    "    \"https://i.ytimg.com/vi/foIrlXp-9Pk/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLDvQNK96cKcZDPgXULuFDjTyL5X4g\"\n",
    "]\n",
    "\n",
    "video_urls = extract_video_urls(thumbnail_urls)\n",
    "\n",
    "for i, video_url in enumerate(video_urls, 1):\n",
    "    print(f\"Video {i}: {video_url}\")\n",
    "\n",
    "\n",
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
    "def extract_video_urls(thumbnail_urls):\n",
    "    video_urls = []\n",
    "    for thumbnail_url in thumbnail_urls:\n",
    "        video_id = thumbnail_url.split('/')[-2]  \n",
    "        video_url = f\"https://www.youtube.com/watch?v={video_id}\"  \n",
    "        video_urls.append(video_url)\n",
    "    return video_urls\n",
    "\n",
    "thumbnail_urls = [\n",
    "    \"https://i.ytimg.com/vi/MwVGbIC5qj0/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&amp;rs=AOn4CLCjBMwmAcVmCS-N9q7pwFM03p5clA\",\n",
    "    \"https://i.ytimg.com/vi/9Yt1qj_Bx4Y/hqdefault.jpg?sqp=-oaymwEcCNACELwBSFXyq4qpAw4IARUAAIhCGAFwAcABBg==&amp;rs=AOn4CLCtH2O5_vwlCHqSrHAE0nvJ2tVD5A\",\n",
    "    \"https://i.ytimg.com/vi/gkguIT1XCo4/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLDB93TeXq6-3g3Hm5080lg4dbwXAA\",\n",
    "    \"https://i.ytimg.com/vi/CCw6oto2WlA/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLBzio66Im5GyBY6V5hs-48_1iaBUA\",\n",
    "    \"https://i.ytimg.com/vi/foIrlXp-9Pk/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&amp;rs=AOn4CLDvQNK96cKcZDPgXULuFDjTyL5X4g\"\n",
    "]\n",
    "\n",
    "video_urls = extract_video_urls(thumbnail_urls)\n",
    "\n",
    "for i, video_url in enumerate(video_urls, 1):\n",
    "    print(f\"Video {i}: {video_url}\")\n",
    "\n",
    "\n",
    "Q3. Write a python program to extract the title of the first five videos.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_titles(video_urls):\n",
    "    try:\n",
    "        titles = []\n",
    "        for url in video_urls:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                title_tag = soup.find('title')\n",
    "                if title_tag:\n",
    "                    title = title_tag.text.split(' - YouTube')[0]  \n",
    "                    titles.append(title.strip())\n",
    "                else:\n",
    "                    titles.append(\"Title not found\")\n",
    "            else:\n",
    "                titles.append(\"Failed to fetch the video page\")\n",
    "\n",
    "        return titles\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=MwVGbIC5qj0\",\n",
    "    \"https://www.youtube.com/watch?v=9Yt1qj_Bx4Y\",\n",
    "    \"https://www.youtube.com/watch?v=gkguIT1XCo4\",\n",
    "    \"https://www.youtube.com/watch?v=CCw6oto2WlA\",\n",
    "    \"https://www.youtube.com/watch?v=foIrlXp-9Pk\"\n",
    "]\n",
    "\n",
    "video_titles = extract_video_titles(video_urls)\n",
    "\n",
    "for i, title in enumerate(video_titles, 1):\n",
    "    print(f\"Video {i} Title: {title}\")\n",
    "\n",
    "\n",
    "Q4. Write a python program to extract the number of views of the first five videos.\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def extract_video_views(video_urls):\n",
    "    try:\n",
    "        views = []\n",
    "        for url in video_urls:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                match = re.search(r'\"viewCount\":\"(\\d+)\"', response.text)\n",
    "                if match:\n",
    "                    view_count = match.group(1)\n",
    "                    views.append(view_count)\n",
    "                else:\n",
    "                    views.append(\"View count not found\")\n",
    "            else:\n",
    "                views.append(\"Failed to fetch the video page\")\n",
    "\n",
    "        return views\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=MwVGbIC5qj0\",\n",
    "    \"https://www.youtube.com/watch?v=9Yt1qj_Bx4Y\",\n",
    "    \"https://www.youtube.com/watch?v=gkguIT1XCo4\",\n",
    "    \"https://www.youtube.com/watch?v=CCw6oto2WlA\",\n",
    "    \"https://www.youtube.com/watch?v=foIrlXp-9Pk\"\n",
    "]\n",
    "\n",
    "video_views = extract_video_views(video_urls)\n",
    "\n",
    "for i, view in enumerate(video_views, 1):\n",
    "    print(f\"Video {i} Views: {view}\")\n",
    "\n",
    "\n",
    "Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
    "    import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_posting_time(video_urls):\n",
    "    try:\n",
    "        posting_times = []\n",
    "        for url in video_urls:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                meta_tags = soup.find_all('meta')\n",
    "                for tag in meta_tags:\n",
    "                    if tag.get('itemprop') == 'uploadDate':\n",
    "                        posting_times.append(tag.get('content'))\n",
    "                        break\n",
    "                else:\n",
    "                    posting_times.append(\"Posting time not found\")\n",
    "            else:\n",
    "                posting_times.append(\"Failed to fetch the video page\")\n",
    "\n",
    "        return posting_times\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "video_urls = [\n",
    "    \"https://www.youtube.com/watch?v=MwVGbIC5qj0\",\n",
    "    \"https://www.youtube.com/watch?v=9Yt1qj_Bx4Y\",\n",
    "    \"https://www.youtube.com/watch?v=gkguIT1XCo4\",\n",
    "    \"https://www.youtube.com/watch?v=CCw6oto2WlA\",\n",
    "    \"https://www.youtube.com/watch?v=foIrlXp-9Pk\"\n",
    "]\n",
    "\n",
    "video_posting_times = extract_video_posting_time(video_urls)\n",
    "\n",
    "for i, posting_time in enumerate(video_posting_times, 1):\n",
    "    print(f\"Video {i} Posting Time: {posting_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
